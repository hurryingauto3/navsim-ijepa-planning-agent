{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57bca6-7424-4ed2-a565-0a656e53b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra.utils import instantiate\n",
    "from PIL import Image\n",
    "from tqdm import tqdm # For progress bars\n",
    "\n",
    "# Assuming these imports are correct based on your environment\n",
    "from navsim.common.dataloader import SceneLoader\n",
    "from navsim.common.dataclasses import SceneFilter, SensorConfig, Scene, Camera, EgoStatus, Trajectory\n",
    "from navsim.planning.simulation.planner.pdm_planner.utils.pdm_geometry_utils import convert_absolute_to_relative_se2_array\n",
    "from planning_agent.PlanningHead import PlanningHead\n",
    "from planning_agent.NavsimTrajectoryDataset import NavsimTrajectoryDataset, collate_fn_skip_none\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826213cd-1c21-445f-b4c7-0569e4e5142e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up SceneLoader...\n"
     ]
    }
   ],
   "source": [
    "SPLIT = \"mini\"\n",
    "FILTER = \"all_scenes\"\n",
    "OPENSCENE_DATA_ROOT = Path(\"../dataset\") # Adjust if necessary\n",
    "NUPLAN_MAPS_ROOT = OPENSCENE_DATA_ROOT / \"nuplan-maps-v1.0\" # Assuming maps are here\n",
    "NUM_HISTORY_FRAMES = 4 # As per SceneFilter default, adjust if needed\n",
    "NUM_FUTURE_FRAMES = 8 # Predicting 4 seconds at 0.5s interval = 8 poses\n",
    "\n",
    "# --- Set up Data Loading ---\n",
    "print(\"Setting up SceneLoader...\")\n",
    "hydra.initialize(config_path=\"../navsim/navsim/planning/script/config/common/train_test_split/scene_filter\", version_base=None)\n",
    "cfg = hydra.compose(config_name=FILTER)\n",
    "scene_filter: SceneFilter = instantiate(cfg)\n",
    "# Ensure SceneFilter matches desired history/future frames\n",
    "scene_filter.num_history_frames = NUM_HISTORY_FRAMES\n",
    "scene_filter.num_future_frames = NUM_FUTURE_FRAMES\n",
    "\n",
    "# Correct paths based on previous debugging\n",
    "navsim_log_path = OPENSCENE_DATA_ROOT / f\"{SPLIT}_navsim_logs\" / SPLIT\n",
    "sensor_blob_path = OPENSCENE_DATA_ROOT / f\"{SPLIT}_sensor_blobs\" / \"sensor_blobs\" / SPLIT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec97e1b-0355-4d8b-b9fa-a25ed3059f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading logs: 100%|██████████| 64/64 [00:09<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3623 scenes for split 'mini'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify only the sensors needed (saves memory/time)\n",
    "# Just need front camera for this setup\n",
    "sensor_config = SensorConfig(\n",
    "    cam_f0=True, # Only need front camera image\n",
    "    cam_l0=False, cam_l1=False, cam_l2=False,\n",
    "    cam_r0=False, cam_r1=False, cam_r2=False,\n",
    "    cam_b0=False, lidar_pc=False\n",
    ")\n",
    "\n",
    "\n",
    "scene_loader = SceneLoader(\n",
    "    data_path=navsim_log_path,\n",
    "    original_sensor_path=sensor_blob_path,\n",
    "    scene_filter=scene_filter,\n",
    "    synthetic_sensor_path=None, # Not using synthetic data here\n",
    "    synthetic_scenes_path=None,\n",
    "    sensor_config=sensor_config, # Use specific config\n",
    ")\n",
    "print(f\"Loaded {len(scene_loader)} scenes for split '{SPLIT}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff56520e-fa1d-4883-8bf6-db5700f9903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading I-JEPA processor and model: facebook/ijepa_vith14_1k\n",
      "I-JEPA model loaded and frozen.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_ID = \"facebook/ijepa_vith14_1k\" # Using ViT-H/14 as loaded before\n",
    "\n",
    "# Training Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 1 # Adjust as needed\n",
    "BATCH_SIZE = 64 # Adjust based on GPU memory\n",
    "NUM_HISTORY_FRAMES = 4 # As per SceneFilter default, adjust if needed\n",
    "NUM_FUTURE_FRAMES = 8 # Predicting 4 seconds at 0.5s interval = 8 poses\n",
    "\n",
    "# I-JEPA Output Dimension (for ViT-H/14)\n",
    "IJEP_DIM = 1280 # ViT-H/14 hidden size is 1280\n",
    "# If you were using ViT-B/16, this would be 768\n",
    "\n",
    "# Ego Status Dimension (vel_x, vel_y, acc_x, acc_y, cmd_left, cmd_straight, cmd_right)\n",
    "EGO_DIM = 2 + 2 + 4 # Now 8 dimensions\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Load Pre-trained I-JEPA Model ---\n",
    "print(f\"Loading I-JEPA processor and model: {MODEL_ID}\")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=True)\n",
    "ijepa_encoder = AutoModel.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "\n",
    "# IMPORTANT: Freeze the I-JEPA encoder parameters\n",
    "for param in ijepa_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "ijepa_encoder.eval() # Set to evaluation mode\n",
    "print(\"I-JEPA model loaded and frozen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bbb512-7f43-4318-8b64-86b0abc160a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset and DataLoader...\n",
      "DataLoader created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Creating Dataset and DataLoader...\")\n",
    "dataset = NavsimTrajectoryDataset(scene_loader, processor, NUM_HISTORY_FRAMES, NUM_FUTURE_FRAMES, DEVICE)\n",
    "# Use the custom collate_fn\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True, \n",
    "                        num_workers=8, \n",
    "                        pin_memory=True, \n",
    "                        drop_last=True, \n",
    "                        collate_fn=collate_fn_skip_none,\n",
    "                        persistent_workers=True)\n",
    "print(\"DataLoader created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc479c0c-b282-4d09-8b02-178bc05240d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Planning Head defined.\n"
     ]
    }
   ],
   "source": [
    "NUM_FUTURE_FRAMES = 8 # Predicting 4 seconds at 0.5s interval = 8 poses\n",
    "IJEP_DIM = 1280 # ViT-H/14 hidden size is 1280\n",
    "EGO_DIM = 2 + 2 + 4 # Now 8 dimensions\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = NUM_FUTURE_FRAMES*3\n",
    "\n",
    "mlp_head = PlanningHead(ijep_dim=IJEP_DIM, ego_dim=EGO_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM).to(DEVICE)\n",
    "print(\"MLP Planning Head defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6da2c9-89c4-496c-87d8-64ced2a31c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/56 [00:00<?, ?it/s]ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted at epoch 1, saved ./checkpoint_failure_epoch1.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/navsim_workspace/code/planning_agent/NavsimTrajectoryDataset.py\", line 115, in collate_fn_skip_none\n    return torch.utils.data.dataloader.default_collate(batch)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/storage.py\", line 1198, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/storage.py\", line 415, in _new_shared\n    return cls._new_using_fd_cpu(size)\nRuntimeError: unable to write to file </torch_57109_1613807916_0>: No space left on device (28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mijepa_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mijepa_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# or path to resume checkpoint\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# save every epoch\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cls_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# or True if you want CLS token\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished. Avg losses per epoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, history)\n",
      "File \u001b[0;32m/navsim_workspace/code/planning_agent/PlanningHead.py:76\u001b[0m, in \u001b[0;36mPlanningHead.fit\u001b[0;34m(self, dataloader, ijepa_encoder, device, epochs, lr, optimizer, criterion, save_dir, resume_from, checkpoint_interval, use_cls_token)\u001b[0m\n\u001b[1;32m     74\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     75\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/navsim/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1480\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1505\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1505\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/_utils.py:733\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/navsim_workspace/code/planning_agent/NavsimTrajectoryDataset.py\", line 115, in collate_fn_skip_none\n    return torch.utils.data.dataloader.default_collate(batch)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n    return [\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 270, in collate_tensor_fn\n    storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/storage.py\", line 1198, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(\n  File \"/opt/conda/envs/navsim/lib/python3.9/site-packages/torch/storage.py\", line 415, in _new_shared\n    return cls._new_using_fd_cpu(size)\nRuntimeError: unable to write to file </torch_57109_1613807916_0>: No space left on device (28)\n"
     ]
    }
   ],
   "source": [
    "history = mlp_head.fit(\n",
    "    dataloader=dataloader,\n",
    "    ijepa_encoder=ijepa_encoder,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    resume_from=None,              # or path to resume checkpoint\n",
    "    checkpoint_interval=1,         # save every epoch\n",
    "    use_cls_token=True            # or True if you want CLS token\n",
    ")\n",
    "\n",
    "print(\"Training finished. Avg losses per epoch:\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b3722-c5a0-4102-84a5-9523a97ac933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navsim",
   "language": "python",
   "name": "navsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
