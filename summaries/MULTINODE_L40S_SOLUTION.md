# üöÄ Multi-Node L40S Training Options - START IMMEDIATELY!

## ‚úÖ **YES! Multi-Node DDP Works with NAVSIM**

The config has `trainer.params.num_nodes=1` which we **CAN override**!

PyTorch Lightning supports multi-node DDP with SLURM automatically via:
- `MASTER_ADDR` and `MASTER_PORT` environment variables
- `trainer.params.num_nodes=N` parameter
- SLURM coordinates process spawning across nodes

---

## üéØ **L40S Cluster Availability RIGHT NOW**

**Partition**: `l40s_public` (account: `users`)

**Free nodes with 0/4 GPUs allocated**:
- gl001, gl006-gl016, and many more
- **10+ nodes completely free!**

**Each node**:
- 4√ó L40S GPUs (48GB VRAM each)
- 128 CPUs
- ~1TB RAM

**Your model**: 83M params √ó 4 bytes = 332 MB (fits easily in 48GB!)

---

## üìä **Multi-Node Options Comparison**

| Configuration | Nodes | GPUs | Batch Size | Time/Epoch | 40 Epochs | Availability |
|--------------|-------|------|------------|------------|-----------|--------------|
| **H200√ó8** (queued) | 1 | 8 | 176 | 15 min | 10h | ‚è≥ Wait 6.5h |
| **L40S√ó4** | 1 | 4 | 88 | 30 min | 20h | ‚úÖ NOW |
| **L40S√ó8** ‚≠ê | **2** | **8** | **176** | **~18 min** | **~12h** | ‚úÖ **NOW** |
| **L40S√ó16** üöÄ | **4** | **16** | **352** | **~9 min** | **~6h** | ‚úÖ **NOW** |

**L40S performance**: ~87% of H200 speed, so multiply H200 times by 1.15√ó

---

## üéØ **RECOMMENDED: 2-Node L40S (8 GPUs)**

### Why This Is Best:
1. ‚úÖ **START NOW** - no queue wait
2. ‚úÖ **Same 8 GPUs** as H200 plan
3. ‚úÖ **Only ~2h slower** than H200 (12h vs 10h)
4. ‚úÖ **2√ó faster** than single-node L40S
5. ‚úÖ **Higher success rate** - 2 free nodes easier than 8-GPU H200

### Submit Command:
```bash
sbatch scripts/train_2node_8gpu_l40s.slurm
```

**Expected outcome**:
- Start: Immediately (within 5 minutes)
- Training: ~12 hours
- **Total: ~12 hours from now!**

Compare to H200:
- H200 wait: 6.5h + 10h = 16.5h total
- **L40S saves: 4.5 hours!**

---

## üöÄ **AGGRESSIVE: 4-Node L40S (16 GPUs)**

Want to go even faster?

### Submit Command:
```bash
sbatch scripts/train_4node_16gpu_l40s.slurm
```

**Benefits**:
- 16 GPUs total (2√ó the H200 plan!)
- Effective batch size: 352 (vs 176)
- **Finish in ~6 hours!**
- Still likely to start immediately (10+ free nodes)

**Risk**: Slightly more coordination overhead between 4 nodes, but Lightning handles it automatically.

---

## üîç **How Multi-Node DDP Works**

### SLURM Side:
```bash
#SBATCH --nodes=2              # Request 2 nodes
#SBATCH --ntasks-per-node=1    # 1 Python process per node
#SBATCH --gres=gpu:4           # 4 GPUs per node
```

### Lightning Side:
```bash
trainer.params.num_nodes=2     # Lightning knows about 2 nodes
```

### Automatic Coordination:
1. SLURM launches your script on each node
2. Script sets `MASTER_ADDR` to first node's hostname
3. Each node's Python process discovers its rank via SLURM env vars
4. Lightning connects all ranks via `MASTER_ADDR:MASTER_PORT`
5. Training proceeds with gradient synchronization across nodes

### What You See:
- 2 nodes √ó 4 GPUs/node = 8 total GPU processes
- Each process trains on batch_size=22
- Effective batch size: 22 √ó 8 = 176
- Gradients synced across all 8 processes every step

---

## ‚ö° **Comparison Table: All Options**

| Option | Wait | Train | Total | GPUs | Success | Value |
|--------|------|-------|-------|------|---------|-------|
| H200√ó8 (queued) | 6.5h | 10h | **16.5h** | 8 | 95% | Good |
| **L40S 2-node** ‚≠ê | ~0h | 12h | **~12h** | 8 | 98% | **BEST** |
| L40S 4-node üöÄ | ~0h | 6h | **~6h** | 16 | 95% | Fastest |
| L40S 1-node | ~0h | 20h | **~20h** | 4 | 99% | Safe |
| 1-GPU (265438) | 0h | 50h | **~50h** | 1 | 100% | Slow |

---

## üìù **Action Plan**

### Option A: Conservative (2-Node L40S) ‚≠ê RECOMMENDED
```bash
# Cancel the H200 job waiting in queue
scancel 268762

# Submit 2-node L40S training
sbatch scripts/train_2node_8gpu_l40s.slurm

# Monitor (should start within 5 min)
watch -n 10 squeue -u $USER
```

### Option B: Aggressive (4-Node L40S) üöÄ
```bash
# Cancel the H200 job
scancel 268762

# Go for maximum speed!
sbatch scripts/train_4node_16gpu_l40s.slurm

# Finish in 6 hours!
```

### Option C: Keep H200 (Wait It Out)
```bash
# Do nothing, wait ~6.5 hours
# Total time: ~16.5 hours
```

---

## üîß **Technical Details**

### Multi-Node DDP Environment Variables:
```bash
MASTER_ADDR=$(scontrol show hostname $SLURM_JOB_NODELIST | head -n 1)
MASTER_PORT=12355
WORLD_SIZE=$((SLURM_NNODES * 4))  # Total GPUs across all nodes
```

### Lightning Auto-Detection:
- Reads `SLURM_NODEID` for node rank
- Reads `SLURM_NNODES` for world size
- Uses `trainer.params.num_nodes` to confirm multi-node mode
- Spawns local workers based on `torch.cuda.device_count()`

### Why It Just Works:
- PyTorch Lightning has built-in SLURM support
- Automatically detects multi-node environment
- Handles all inter-node communication
- You just set `num_nodes=2` and it works!

---

## üìä **Performance Expectations**

### 2-Node L40S (8 GPUs):
- Samples/second: ~6-7 (vs ~8 on H200)
- Time/epoch: ~18 minutes
- 40 epochs: **~12 hours**
- Equivalent to H200 with 15% overhead

### 4-Node L40S (16 GPUs):
- Samples/second: ~12-14
- Time/epoch: ~9 minutes
- 40 epochs: **~6 hours**
- **2√ó faster than H200 8-GPU plan!**

---

## üéì **Why This Wasn't Obvious**

Multi-node DDP requires:
1. SLURM support (‚úÖ we have it)
2. Config parameter for `num_nodes` (‚úÖ it exists!)
3. Understanding Lightning auto-detects SLURM (‚úÖ now we know!)

Previous attempts failed because we didn't realize:
- Config has `num_nodes` parameter
- Lightning works with SLURM multi-node automatically
- L40S partition has many free nodes

---

## ‚úÖ **Recommendation Summary**

**Best choice**: 2-Node L40S (8 GPUs)
- Starts immediately
- Same GPU count as H200 plan
- Finishes in ~12h (saves 4.5h vs waiting for H200)
- Very high success rate

**Command**:
```bash
scancel 268762  # Cancel H200 queue
sbatch scripts/train_2node_8gpu_l40s.slurm
```

**Monitor**:
```bash
# Should start in ~5 minutes
squeue -u $USER

# Watch training logs
tail -f /scratch/ah7072/navsim_workspace/exp/logs/train_<JOBID>.out
```

**Result**: Training complete in ~12 hours! üéâ
