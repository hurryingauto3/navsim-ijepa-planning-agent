#!/bin/bash
# Script to clean up redundant SLURM scripts
# Run with: bash cleanup_scripts.sh

echo "üßπ Cleaning up redundant scripts..."

# Create backup directory
BACKUP_DIR="/scratch/ah7072/scripts/backup_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "üì¶ Backup directory: $BACKUP_DIR"

# ============================================
# REDUNDANT CACHING SCRIPTS (failed attempts)
# ============================================
echo ""
echo "Moving REDUNDANT caching scripts to backup..."

# These all failed or are duplicates
REDUNDANT_CACHE=(
    "cache_1gpu.slurm"                          # Failed: Ray OOM
    "cache_ray_gpu.slurm"                       # Failed: Ray OOM
    "cache_ray_limited.slurm"                   # Duplicate attempt
    "cache_sequential_gpu.slurm"                # Unnecessary fallback
    "cache_best.slurm"                          # ThreadPool - didn't work
    "cache_training_features.slurm"             # Old naming
    "cache_training_features_parallel.slurm"    # Duplicate
    "cache_training_features_gpu.slurm"         # Duplicate
)

for script in "${REDUNDANT_CACHE[@]}"; do
    if [ -f "/scratch/ah7072/scripts/$script" ]; then
        mv "/scratch/ah7072/scripts/$script" "$BACKUP_DIR/"
        echo "  ‚úì Moved $script"
    fi
done

# ============================================
# REDUNDANT TRAINING SCRIPTS (failed DDP)
# ============================================
echo ""
echo "Moving REDUNDANT training scripts to backup..."

REDUNDANT_TRAIN=(
    "torch_train_8gpu.slurm"                    # Wrong: gres=gpu:h200:1 (only 1 GPU!)
    "torch_train_8gpu_spawn.slurm"              # Failed DDP attempt
    "torch_train_8gpu_torchrun.slurm"           # Failed torchrun attempt
    "torch_train_4gpu.slurm"                    # Duplicate/unnecessary
    "torch_train_optimized.slurm"               # Unclear purpose
    "torch_train_pdm.slurm"                     # Specific variant (can keep if needed)
    "torch_train_w.slurm"                       # Specific variant (can keep if needed)
    "torch_train_w_ep.slurm"                    # Specific variant (can keep if needed)
)

for script in "${REDUNDANT_TRAIN[@]}"; do
    if [ -f "/scratch/ah7072/scripts/$script" ]; then
        mv "/scratch/ah7072/scripts/$script" "$BACKUP_DIR/"
        echo "  ‚úì Moved $script"
    fi
done

# ============================================
# SUMMARY
# ============================================
echo ""
echo "‚úÖ Cleanup complete!"
echo ""
echo "üìÅ KEEPING (useful scripts):"
echo "  - train_8gpu_ddp_fixed.slurm    ‚≠ê NEW: Correct 8-GPU DDP"
echo "  - torch_train_1gpu.slurm         ‚úì Working single GPU baseline"
echo "  - cache_ray_1gpu.slurm           üîß In-progress caching solution"
echo "  - cache_navtrain_parallel.slurm  üîß Alternative approach"
echo "  - torch_smoke_test.slurm         ‚úì Testing"
echo "  - torch_eval.slurm               ‚úì Evaluation"
echo "  - launch_*.sh                    ‚úì Batch launchers"
echo "  - *.md, *.sh                     ‚úì Documentation & utilities"
echo ""
echo "üóëÔ∏è  BACKED UP to: $BACKUP_DIR"
echo "    (10+ redundant/failed scripts)"
